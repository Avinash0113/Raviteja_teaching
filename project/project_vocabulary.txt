client : Micron Technologies
Address: XX
Team: Test execution team
Domain: Memory

Memory based products: 
RAM- DRAM, SRAM
ROM- HDD,SSD

___________________________________________________________________________________________________
Toshibha, Intel, Western digital(WDC/WD), sandisk, skhynix, Micron, Samsung --> Memory based products

1. end-user = amazon/flipkart
2. Customer(OEM- original Equipement Manufacturer): Lenovo, Dell, Hp, THinkpad, Acer
3. Data center = facebook, Amazon, Alibaba, Google, Microsoft, 

generic tests(applicable to customer)*customer specific tests

Total tests = 5000
generic tests = 3000
Dell = 4000 = 3000+1000
Microsoft = 3700 = 3000+700
_______________________________________________________________________________________________________
Team structure:

1. Firmware team: 50
Firmware: Any electronic device will work based on firmware/binary/firmware program
Eg: Washing machine, TV, AC
programming language: Embedded C, C
Storage protocols(specification pdf based on which they will develop) Eg: NVMe, PCIe, MI


2. Firmware Validation team :30
work: They will write test cases -5000 in embedded python/python to validate the firmware developed by Firmware team.
programming language: Embedded python, python
Storage protocols(specification pdf based on which they will develop) Eg: NVMe, PCIe, MI


3. Test execution/Framework Automation Team: 5
work: Need to develop an environment that can run/pick validation scripts based upon OEM(customer) and generate the results,logs,reports and raise the bugs.
Framework name: MSVP : Mutli System validation platform

os/platform: Windows, Azure, (linux)

windows vs Azure

conval = conval validation
a) Framework Automation/Test execution Automation
why?
Need to develop an environment
Skills:  Resume mentioned skills

conval : Need to Continuously validate a set of test cases applicable for given memory product based on generic/customer requirement and generate logs, inspect the logs and give a consolidated conval report.

Need fix our exisiting scripts in case of programming errors
Need to develope new scripts if new requirement comes

b) Manual Testing

Report the bug: If Test script fails, need to report to validation/FW team using jira dashboard
19@@


4. System setup team/hardware
--> They will ready systems for execution with all hardwares in place.

_______________________________________________________________________________

customers: Toshibha, Intel, Western digital(WDC/WD), sandisk, skhynix, Micron, Samsung
product: DRAM, SRAM, SSD, HDD
product version: Epic, Eagle, ELAN
___________________________________________________________________________________________________
Test life cycle
_________________________________

1. Pre conditioning: On which date,time,file name, which IP, capacity system,  which firmware, which config, Need to check SSD connected or not, Need to flash firmwares and configs using API based on trigger file

@System_info
2. Setup: Need to set registers and check the firmware support for the validation feature.
3. workload: Actual test validation based on spec.
4. teardown: whatever modifications we have done, we need to set back those to setup phase.

5. post conditioning: Need to check SSD connected or not, if not collect system logs.

_________________________________
host machine = Test PC
local machine = laptop



nmap(Available systems, nmap, subprocess, re)--> request API post(bypass with static json file) --> request API get  --> system Ips

windows  --> windowscredentials.json
azure  --> azurecredentials.json
linux  -> some other team 

ip
credentials


nmap -p 9001 42




raviteja.json  10 20 30 40 raviteja.py